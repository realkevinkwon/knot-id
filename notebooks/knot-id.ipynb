{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIAOzEUn_jZv"
      },
      "source": [
        "# Knot ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpCTmufo_jZw"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOa4Cdm6_jZx"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsWp2-pr_jZx"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from google.colab import drive\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL8cSifFC3GL"
      },
      "source": [
        "### Google Drive setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNnot8p1C5ir"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7uNbWsVBQ18"
      },
      "source": [
        "### GPU setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld-nzZDsBVWP"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nur3Ewr8_jZy"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ekIMln8_jZy"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "img_size = 32\n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "test_split = 0.2\n",
        "train_split = 1.0 - test_split\n",
        "learning_rate = 1e-2\n",
        "crop_size = 3456\n",
        "data_root = '/content/drive/MyDrive/colab-datasets/knot-id/data'\n",
        "data_dir = '10Knots_32'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip data"
      ],
      "metadata": {
        "id": "g3DTbaM1rRQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('/content/drive/MyDrive/colab-datasets/knot-id/data/10Knots_32.zip', 'r') as zip_file:\n",
        "    zip_file.extractall(data_root)"
      ],
      "metadata": {
        "id": "WrDFU3gxrT_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBZXv2oQ_jZy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvqp-Hmj_jZy"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtoPVu4a_jZy"
      },
      "outputs": [],
      "source": [
        "class Knots(VisionDataset):\n",
        "\n",
        "    def __init__(self, data_root='.', data_dir='10Knots', transform=None):\n",
        "        self.transform = transform\n",
        "        self.filepaths = []\n",
        "        self.targets = []\n",
        "        self.classes = {}\n",
        "        self.data_path = os.path.join(data_root, data_dir)\n",
        "\n",
        "        super().__init__(data_root, transforms=None, transform=transform)\n",
        "\n",
        "        class_idx = 0\n",
        "        for filename in os.listdir(self.data_path):\n",
        "            if filename != '.DS_Store':\n",
        "                self.classes[class_idx] = filename\n",
        "                class_idx += 1\n",
        "        \n",
        "        for idx, label in self.classes.items():\n",
        "            for path, _, filenames in os.walk(os.path.join(self.data_path, label)):\n",
        "                for filename in filenames:\n",
        "                    if filename != '.DS_Store':\n",
        "                        self.filepaths.append(os.path.join(path, filename))\n",
        "                        self.targets.append(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.filepaths[idx])\n",
        "        target = self.targets[idx]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def get_class(self, target):\n",
        "        return self.classes[target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLm8190J_jZz"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJn_OcCr_jZz"
      },
      "outputs": [],
      "source": [
        "class KnotClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(KnotClassifier, self).__init__()\n",
        "\n",
        "        # input shape (64, 3, 32, 32)\n",
        "        self.feature_learning = nn.Sequential(\n",
        "            nn.Conv2d(3, 10, 3, 1, 1),      # (64, 10, 32, 32)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                # (64, 10, 16, 16)\n",
        "            nn.Conv2d(10, 20, 3, 1, 1),     # (64, 20, 16, 16)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                # (64, 20, 8, 8)\n",
        "        )\n",
        "\n",
        "        self.classification = nn.Sequential(\n",
        "            nn.Flatten(1),                  # (64, 1280)\n",
        "            nn.Linear(1280, 256),           # (64, 256)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,64),              # (64, 64)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,10)                # (64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_learning(x)\n",
        "        x = self.classification(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1rTJ9t7_jZ0"
      },
      "source": [
        "## Train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1lfMnLb_jZ0"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, loss_fn, optimizer, epoch):\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (images, targets) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        output = model(images)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(\n",
        "                f'Epoch {epoch}: [{batch_idx*len(images)}/{len(train_loader.dataset)}]'\n",
        "                f'Loss: {loss.item():.4f}'\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNm-LYBh_jZ0"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, loss_fn, epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, targets in test_loader:\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            \n",
        "            output = model(images)\n",
        "\n",
        "            test_loss += loss_fn(output, targets, reduction='sum').item()\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(targets.data.view_as(pred)).sum()\n",
        "\n",
        "            test_loss /= len(test_loader.dataset)\n",
        "            print(\n",
        "                f'Test result on epoch {epoch}: '\n",
        "                f'Avg loss is {test_loss:.4f}, '\n",
        "                f'Accuracy: {(100.0 * correct / len(test_loader.dataset)):.2f}%'\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_AoGv99_jZ0"
      },
      "source": [
        "## Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH3Rb1TF_jZ1"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(crop_size),\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.7019, 0.4425, 0.1954), (0.1720, 0.1403, 0.1065))\n",
        "])\n",
        "\n",
        "train_data, test_data = random_split(Knots(data_root=data_root, data_dir=data_dir, transform=transform), [train_split, test_split])\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = KnotClassifier()\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    train(model, train_loader, loss_fn, optimizer, epoch)\n",
        "    test(model, test_loader, loss_fn, epoch)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "03bb1b95e98afcf6a2640b6976662dfa86aafc795349b15c3689776271668947"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}