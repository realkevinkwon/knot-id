{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knot ID"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "img_size = 32\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "test_split = 0.2\n",
    "train_split = 1.0 - test_split\n",
    "learning_rate = 1e-2\n",
    "crop_size = 3456"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Knots(VisionDataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        self.root = './data/'\n",
    "        self.transform = transform\n",
    "        self.filepaths = []\n",
    "        self.targets = []\n",
    "        self.classes = {}\n",
    "\n",
    "        super().__init__(self.root, transforms=None, transform=transform)\n",
    "\n",
    "        class_idx = 0\n",
    "        for filename in os.listdir(os.path.join(self.root, '10Knots')):\n",
    "            if filename != '.DS_Store':\n",
    "                self.classes[class_idx] = filename\n",
    "                class_idx += 1\n",
    "        \n",
    "        for idx, label in self.classes.items():\n",
    "            for path, _, filenames in os.walk(os.path.join(self.root, '10Knots', label)):\n",
    "                for filename in filenames:\n",
    "                    if filename != '.DS_Store':\n",
    "                        self.filepaths.append(os.path.join(path, filename))\n",
    "                        self.targets.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.filepaths[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def get_class(self, idx):\n",
    "        return self.classes[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnotClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(KnotClassifier, self).__init__()\n",
    "\n",
    "        # input shape (64, 3, 32, 32)\n",
    "        self.feature_learning = nn.Sequential(\n",
    "            nn.Conv2d(3, 10, 3, 1, 1),      # (64, 10, 32, 32)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                # (64, 10, 16, 16)\n",
    "            nn.Conv2d(10, 20, 3, 1, 1),     # (64, 20, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                # (64, 20, 8, 8)\n",
    "        )\n",
    "\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Flatten(1),                  # (64, 1280)\n",
    "            nn.Linear(1280, 256),           # (64, 256)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,64),              # (64, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,10)                # (64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_learning(x)\n",
    "        x = self.classification(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_fn, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f'Epoch {epoch}: [{batch_idx*len(images)}/{len(train_loader.dataset)}]'\n",
    "                f'Loss: {loss.item():.4f}'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_fn, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            output = model(images)\n",
    "            test_loss += loss_fn(output, targets, reduction='sum').item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(targets.data.view_as(pred)).sum()\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            print(\n",
    "                f'Test result on epoch {epoch}: '\n",
    "                f'Avg loss is {test_loss:.4f}, '\n",
    "                f'Accuracy: {(100.0 * correct / len(test_loader.dataset)):.2f}%'\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(crop_size),\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.7019, 0.4425, 0.1954), (0.1720, 0.1403, 0.1065))\n",
    "])\n",
    "\n",
    "train_data, test_data = random_split(Knots(transform=transform), [train_split, test_split])\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = KnotClassifier()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(model, train_loader, loss_fn, optimizer, epoch)\n",
    "    test(model, test_loader, loss_fn, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03bb1b95e98afcf6a2640b6976662dfa86aafc795349b15c3689776271668947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
