{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIAOzEUn_jZv"
      },
      "source": [
        "# Knot ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpCTmufo_jZw"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOa4Cdm6_jZx"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GsWp2-pr_jZx"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive setup"
      ],
      "metadata": {
        "id": "CL8cSifFC3GL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vNnot8p1C5ir",
        "outputId": "5b4c1e4d-be52-4f2b-84d3-fdd5f3834027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU setup"
      ],
      "metadata": {
        "id": "t7uNbWsVBQ18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Ld-nzZDsBVWP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nur3Ewr8_jZy"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6ekIMln8_jZy"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "img_size = 32\n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "test_split = 0.2\n",
        "train_split = 1.0 - test_split\n",
        "learning_rate = 1e-2\n",
        "crop_size = 3456"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBZXv2oQ_jZy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvqp-Hmj_jZy"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jtoPVu4a_jZy"
      },
      "outputs": [],
      "source": [
        "class Knots(VisionDataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "        self.root = './data/'\n",
        "        self.transform = transform\n",
        "        self.filepaths = []\n",
        "        self.targets = []\n",
        "        self.classes = {}\n",
        "\n",
        "        super().__init__(self.root, transforms=None, transform=transform)\n",
        "\n",
        "        class_idx = 0\n",
        "        for filename in os.listdir(os.path.join(self.root, '10Knots')):\n",
        "            if filename != '.DS_Store':\n",
        "                self.classes[class_idx] = filename\n",
        "                class_idx += 1\n",
        "        \n",
        "        for idx, label in self.classes.items():\n",
        "            for path, _, filenames in os.walk(os.path.join(self.root, '10Knots', label)):\n",
        "                for filename in filenames:\n",
        "                    if filename != '.DS_Store':\n",
        "                        self.filepaths.append(os.path.join(path, filename))\n",
        "                        self.targets.append(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.filepaths[idx])\n",
        "        target = self.targets[idx]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def get_class(self, idx):\n",
        "        return self.classes[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLm8190J_jZz"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OJn_OcCr_jZz"
      },
      "outputs": [],
      "source": [
        "class KnotClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(KnotClassifier, self).__init__()\n",
        "\n",
        "        # input shape (64, 3, 32, 32)\n",
        "        self.feature_learning = nn.Sequential(\n",
        "            nn.Conv2d(3, 10, 3, 1, 1),      # (64, 10, 32, 32)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                # (64, 10, 16, 16)\n",
        "            nn.Conv2d(10, 20, 3, 1, 1),     # (64, 20, 16, 16)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                # (64, 20, 8, 8)\n",
        "        )\n",
        "\n",
        "        self.classification = nn.Sequential(\n",
        "            nn.Flatten(1),                  # (64, 1280)\n",
        "            nn.Linear(1280, 256),           # (64, 256)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,64),              # (64, 64)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,10)                # (64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_learning(x)\n",
        "        x = self.classification(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1rTJ9t7_jZ0"
      },
      "source": [
        "## Train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s1lfMnLb_jZ0"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, loss_fn, optimizer, epoch):\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (images, targets) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        output = model(images)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(\n",
        "                f'Epoch {epoch}: [{batch_idx*len(images)}/{len(train_loader.dataset)}]'\n",
        "                f'Loss: {loss.item():.4f}'\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TNm-LYBh_jZ0"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, loss_fn, epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, targets in test_loader:\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            \n",
        "            output = model(images)\n",
        "\n",
        "            test_loss += loss_fn(output, targets, reduction='sum').item()\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(targets.data.view_as(pred)).sum()\n",
        "\n",
        "            test_loss /= len(test_loader.dataset)\n",
        "            print(\n",
        "                f'Test result on epoch {epoch}: '\n",
        "                f'Avg loss is {test_loss:.4f}, '\n",
        "                f'Accuracy: {(100.0 * correct / len(test_loader.dataset)):.2f}%'\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_AoGv99_jZ0"
      },
      "source": [
        "## Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TH3Rb1TF_jZ1",
        "outputId": "3f84555c-9829-4424-bcc5-c65e1fdd9490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-054a6064fb16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m ])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKnots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-bec152664e47>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, transform)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mclass_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10Knots'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'.DS_Store'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/10Knots'"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(crop_size),\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.7019, 0.4425, 0.1954), (0.1720, 0.1403, 0.1065))\n",
        "])\n",
        "\n",
        "train_data, test_data = random_split(Knots(transform=transform), [train_split, test_split])\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = KnotClassifier()\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    train(model, train_loader, loss_fn, optimizer, epoch)\n",
        "    test(model, test_loader, loss_fn, epoch)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "03bb1b95e98afcf6a2640b6976662dfa86aafc795349b15c3689776271668947"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}